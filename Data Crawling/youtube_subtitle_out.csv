y
so when you're learning you know the
basics of algorithmic
models now you'll have to confront
questions of algorithmic bias
and fairness it won't be if you're
interested in that go
take the class in the philosophy
department it will be built into the
core classes in cs
[Music]
i think we're already witnessing some of
the uh the harm
and damage being made by the adoption of
algorithms and ai
in like the biases that exist
in some of the tools and the spread of
discrimination and
distrust in the media and all of that to
deal with that
potential threat and harm like who do
you think
is most important to be educated and
like will
informed consumers be most critical
or informed developers or inform the
government
[Music]
well i think all of the above is
important and
at the end of the day i wouldn't leave
this just to consumers however
because that's a kind of one by one
approach
that doesn't leave possible a kind of
broader or collective strategy
so you know some people say they're so
fed up with facebook
that the only responsible thing to do is
to delete facebook from your phone
or your smartphone is so filled with
notification devices and various ways to
hack your attention
that you should you know like turn the
color off and make it grayscale
and like that's the power of a consumer
if that's the sum
total of our kind of possible actions
that i think human beings are going to
lose out in the end
i'll give you just one example in the
space of say you know content moderation
or content regulation
what i have in mind so in the united
states
when you used to be able to go to a
movie theater
the movies are all rated you know g or
pg or r
or no content that is not a law that was
passed by
the us government it's a voluntary
industry collaboration
to self-regulate and to give information
to consumers so they can make informed
decisions about whether or not they wish
to
allow their children to see a movie or
if it's rated r there's an age cut off
that's an example that sits above the
consumer and is below the government
so that's i want to emphasize our
choices are not just
let the individual user decide or let
government regulate
we have lots of other options in between
[Music]
one of the great things about being a
university is that we get to teach
19 20 21 year old kids and
these are the kids that are going to end
up in 10 years in positions of
leadership and responsibility
so we can think actually about how do we
want to educate
people for the next 10 years so that 30
years from now
the world looks like a different place i
mean i think it's a great transition to
your ethics curriculum that you're
supporting campus
hey can you tell us about the new
curriculum how you're adopting it and
is there any early wins that you have
witnessed
well we're doing a bunch of really
exciting things much of it
driven by hai style thinking and with
support from people like you so i'm
really excited about
two different efforts that complement
each other
one is what we call embedded ethics and
the idea
is not to tell the computer science
professor who doesn't have
the kind of philosophical training to
include
genuinely robust content in ethics in
his or her courses
but now working in collaboration with
someone who does have that training
we're developing modules for each of the
core courses
that will expose every single student at
stanford who's a cs major to
ethical frameworks and ethical questions
about ai
and you know computer science more more
broadly so when you're learning
you know the basics of algorithmic
models now
you'll have to confront questions of
algorithmic bias
and fairness it will be built into the
core classes to cs
now there's a second initiative and this
is one that i'm also personally involved
in which is
a large introductory course and the
large introductory course combines me
the
philosopher a colleague who's a social
scientist that has experience in public
policy
and then a computer science professor so
this is the only course we know
at stanford at least that combines
technical assignments
policy memos and philosophy papers in
the same class
so we wanted to make this a large class
it enrolls about 300 people
right that's great i mean i think that's
wonderful that
stanford has adopted that curriculum and
offered to
the young students so those are
available
those learnings and curriculums are
available for yes
all the materials are our creative
commons license and
they'll be assembled on a website
together the website for the class i
just
described is cs182.stanford.edu you can
download all the case studies all of the
readings as long as they're not
copyrighted
and you know similar for the modules
that we're developing in the embedded
ethics initiative we would love for
other people to use them in their
company at their other universities
they're meant for for everybody
[Music]
according to that we don't necessarily
exercise
everything we learned in kindergarten
are you hopeful that
those who took those courses and lessons
will
practice what they learned throughout
their career
yeah that's a great question i have to
remind people that
there are at least three different
levels of thinking about ethics
and the first level and the least
interesting level to me
at least is personal ethics human beings
are imperfect
almost no one is a moral saint we all
suffer from various flaws
and so the goal for us shouldn't be that
we need an ethics course as if it's a
kind of
like a vaccine against future bad
behavior
much more interesting are a second level
and a third level of ethics the second
level is
professional ethics what are the
professional norms and structures
that should bind people together in
their professional activity
now the classic one is you know doctors
or medical healthcare providers who have
the hippocratic oath of do no harm
plus a whole set of other norms that
guide their own practice
um i think we could develop a much
broader set of professional norms for ai
scientists
and that would be a good contribution
and then of course the
the final level the third level is
political or social ethics
how should we think about the
institutions that shape our own behavior
and how do we design better institutions
so that
whatever human behavior is it's
channeled in general to a better
direction
yeah we all knew that you shouldn't lie
cheat or steal
don't be lance armstrong the olympic
bicyclist
or the the tour de france winner who
doped himself in order to win
don't be elizabeth holmes the stanford
dropout who created theranos but was
deceiving people about the power of the
technology
we don't need ender's classes to tell
people don't lie cheat or steal
if you didn't learn that by the time you
showed up to stanford it's already too
late
what we need are ethics classes at a
level of institutional arrangements
confronting value trade-offs intentions
the kinds of things which are
part and parcel of any responsible
person's life
fantastic thank you so much again for
your time and
sharing your thoughts all right so hope
we can do this in person
at some point in the future wouldn't
that be nice i'd love to meet people
uh you know in your part of the world
and have conversations as well
and would love to welcome anyone here to
campus
in the future too thank you thank you so
much
great super thank you so much
