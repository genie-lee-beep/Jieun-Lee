{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Model Evaluation Metric] Classifier Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Confusion Matrix\n",
    "### 1) Accuracy (정확도)\n",
    "Accuracy in classification problems is the number of correct predictions made by the model over all kinds predictions made\n",
    "\n",
    "분류 문제(Classification problem)에서 Accuracy는 모든 예측값에 대하여 올바르게 예측된 값을 나타냅니다.\n",
    "\n",
    "Accuracy는 양성을 양성이라고 예측하고 음성을 음성이라고 예측한 확률을 말합니다.\n",
    "\n",
    "즉, 예측 결과가 실제 값과 얼마나 정확하게 맞는 지를 평가하는 지표\n",
    "\n",
    "\n",
    "#### 1. sklearn에서 제공하는 classifier 객체의 score 메서드\n",
    "- classifier_model.score(X_test, y_test) # Return the mean accuracy on the given test data and labels\n",
    "\n",
    "#### 2. sklearn.metrics의 accuracy_score 메서드를 사용하면 accuracy score를 구할 수 있습니다\n",
    "- accuracy_score(y_test, preds)\n",
    "- from sklearn.metrics import accuracy_score 를 해주어야 합니다.\n",
    "- Accuracy is good measure when the target variable class in the data are nearly balanced. example Survived(60%-yes, 40% no)\n",
    "- Accuracy score는 target variable이 거의 균등할때 사용하면 좋습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import matplotlib\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 데이터 셋 불러오기\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data  #입력\n",
    "y = cancer.target # 출력 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(1, 2, figsize=(12, 4)) \n",
    "# y.value_counts().plot.pie(autopct='%1.1f%%', ax=ax[0]) \n",
    "# sns.countplot(y, data=X_, ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02 데이터 셋 나누기 및 학습\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y ,\n",
    "                                                    stratify=cancer.target, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sklearn에서 제공하는 classifier 객체의 score 메서드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습용 세트 정확도 : 1.000\n",
      "테스트 세트 정확도 : 0.958\n"
     ]
    }
   ],
   "source": [
    "# 03 트리5개로 구성된 랜덤 포레스트 모델 만들기\n",
    "model = RandomForestClassifier(n_estimators=5, random_state=0) # 5개의 트리\n",
    "model.fit(X_train, y_train)  #모델 학습\n",
    "\n",
    "print(\"학습용 세트 정확도 : {:.3f}\".format(model.score(X_train, y_train))) # score가 분류문제에서는 정확도가 찍히고, 회기문제에서는 결정도가 찍힘\n",
    "print(\"테스트 세트 정확도 : {:.3f}\".format(model.score(X_test, y_test)))  #\n",
    "\n",
    "\n",
    "\n",
    "#0.973 의 결과는 테스트세트에서 97.3% 를 정확히 예측했다는 의미이다. (실행할 때마다 결과가 달라진다)\n",
    "#train data가 test data보다 성능이 더 좋음 > 오버피팅이 되어 있음.\n",
    "#RandomForestClassifier의 parameter를 조정 ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict()는 테스트 데이터의 분류 결과를 예측합니다. (회귀에서는>> 반환값이 예측 확률입니다.)\n",
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. sklearn.metrics의 accuracy_score 메서드를 사용하면 accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.958041958041958"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) f1-score\n",
    "F1 score is the weighted average of Precision and Recall.   \n",
    "Therefore, this score takes both false positives and false negatives into account.  \n",
    "Intuitively it is not as easy to understand as accuracy,   \n",
    "but F1 is usually more useful than accuracy, especially if you have an uneven class distribution\n",
    "\n",
    "- f1-score는 Precision과 Recall에 대한  가중 평균(weighted average)입니다.\n",
    "- f1-score는 데이터가 imbalance할 때 측정 도구로 사용하면 좋습니다\n",
    "- 우리가 마주치는 대부분의 데이터는 불균형한 데이터의 분포를 갖기에 f1-scroe를 알아두시면 모델을 평가하는데 많은 도움이 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.94        53\n",
      "           1       0.95      0.99      0.97        90\n",
      "\n",
      "    accuracy                           0.96       143\n",
      "   macro avg       0.96      0.95      0.95       143\n",
      "weighted avg       0.96      0.96      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 정확도는 96%입니다. \n",
    "\n",
    "f1-score를 보면 macro, weigted가 존재합니다. 두 값의 차이는 무엇일까요?\n",
    "\n",
    "macro avg: 단순평균값\n",
    "weighted avg: 각 클래스에 속하는 표본의 갯수로 가중평균값\n",
    "다시 한 번 해석해보면 우리의 모델은  단순평균값으로는 95%의 f1-score를 보이며 가중평균으로는 0.96의 f1-score를 나타냅니다.\n",
    "\n",
    "Accuracy와도 크게 차이가 나지않는것 보면 클래스 불균형으로 인한 문제는 적어보입니다.\n",
    "\n",
    "\n",
    "\n",
    "출처: https://deepinsight.tistory.com/173 [Steve-Lee's Deep Insight]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
