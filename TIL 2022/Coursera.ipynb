{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 원하는 데이터 목록까지 접근하기\n",
    "원하는 데이터 목록까지 접근을 위해 Selenium을 이용하도록 한다. 여기서는 한식 목록까지 접근하는 것을 말한다. \n",
    "\n",
    "Selenium\n",
    "- Selenium WebDriver는 웹 어플리케이션을 테스팅할 때 사용하실 수 있는 무료 도구이며, API를 제공하는 오픈소스 프레임워크\n",
    "- beautiful soup에서 다룰 수 없는 동적인 부분은 selenium을 이용한다.\n",
    "\n",
    "## 1.1 Selenium 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\dell\\anaconda3\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from selenium) (1.25.11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 web driver 설치\n",
    "- 크롬을 사용한 스크래핑을 진행할 예정이기 때문에 chrome web driver를 다운받아 사용하도록 한다.\n",
    "- \n",
    "web driver 다운로드: https://chrome.softwaredownload.co.in/chrome-94-0-4606"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#driver.get() 을 쓰면서 페이지를 이동하면서 원하는 태그들을 가져오는 것임\n",
    "bs_url= \"https://www.consumeraffairs.com\"\n",
    "plus = '/education/online-courses/coursera.html?page=#scroll_to_reviews=true'\n",
    "driver.get(bs_url)\n",
    "# kor= https://www.mangoplate.com/search/%ED%95%9C%EC%8B%9D?keyword=%ED%95%9C%EC%8B%9D&page=1\n",
    "# chinese = https://www.mangoplate.com/search/%EC%A4%91%EC%8B%9D?keyword=%EC%A4%91%EC%8B%9D&page=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 검색창에 검색어 입력 후 검색 버튼 클릭까지 \n",
    "드디어 한식 목록을 불러왔다!\n",
    "1. 검색어 입력: input_b.send_keys(\"단어입력\")   \n",
    "2. 누르고자 하는 버튼의xpath 코드입력: input_c=driver.find_element_by_xpath('/html/body/main/article/header/div/fieldset/input') \n",
    "3. 2번의 버튼 클릭: input_c.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터 가져오기\n",
    "Beautifulsoup\n",
    "HTML과 XML 문서의 parsing을 하기 위한 Python 라이브러리\n",
    "## 2.1 beautifulsoup 설치\n",
    "우선 beautifulsoup 패키지를 다운받아 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from bs4) (4.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 데이터 가져오기 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import ActionChains #더보기 버튼이 숨어있음\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-4f6d4727e8e6>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-4f6d4727e8e6>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    res_lis=soup.find_all('div',class=\"rvw-bd\")\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step1. 1~5페이지 다 가져오기, bs_url+plus+str(z+1)\n",
    "for z in range(5): # 0부터~5이니까 \n",
    "    driver.get(bs_url+plus+str(z+1))\n",
    "    soup= BeautifulSoup(driver.page_source, 'lxml')\n",
    "    res_lis=soup.find_all('div',class=\"rvw-bd\")\n",
    "\n",
    "    # Step1안에서 돌려야 하니까 한칸 들여쓰기 \n",
    "#     for i in range(30):#20개 식당 정보를 다 가져옴\n",
    "#         lin=res_lis[i].find('div').get('p')\n",
    "#         lin=res_lis[i].find('a').get('href')\n",
    "#         driver.get(bs_url+lin) #link로 가기\n",
    "\n",
    "        #스크롤해서 더보기 버튼까지 내리기\n",
    "#         some_tag = driver.find_element_by_xpath('/html/body/main/article/div[1]/div[1]/div/section[3]/ul/li[5]')\n",
    "#         ActionChains(driver).move_to_element(some_tag).perform()  \n",
    "#         btn_m=driver.find_element_by_xpath('/html/body/main/article/div[1]/div[1]/div/section[3]/div[2]')\n",
    "#         btn_m.click()  #스크롤후 더 보기 클릭\n",
    "\n",
    "\n",
    "#         # 새로운 창이니까 다시 beautifulsoup 해주기\n",
    "#         soup1= BeautifulSoup(driver.page_source, 'lxml')\n",
    "#         body=soup1.find('tbody').find_all('tr')\n",
    "#         nam.append(soup1.find('h1',class_='restaurant_name').text)\n",
    "#         adr.append(soup1.find('span',class_='Restaurant__InfoAddress--Text').text)\n",
    "#         num.append(body[1].find('td').text)\n",
    "#         kind.append(body[2].find('td').text)\n",
    "#         rev=driver.find_elements_by_class_name('RestaurantReviewItem__ReviewText')  # rev이라는 리스트 변수로 만들어 주기(지역변수)\n",
    "#         #왜 처음 리뷰수만큼만 받을까?\n",
    "#         #print(len(rev))\n",
    "\n",
    "#         if len(rev)>=3:\n",
    "#                 sev1.append(rev[0].text)\n",
    "#                 sev2.append(rev[1].text)\n",
    "#                 sev3.append(rev[2].text)\n",
    "#     #             sev4.append(rev[3].find('p',class_='RestaurantReviewItem__ReviewText').text)\n",
    "#     #             sev5.append(rev[4].find('p',class_='RestaurantReviewItem__ReviewText').text)\n",
    "#         else:\n",
    "#             sev1.append('리뷰부족')\n",
    "#             sev2.append('리뷰부족')\n",
    "#             sev3.append('리뷰부족')\n",
    "\n",
    "#         import time\n",
    "#         time.sleep(3)\n",
    "    \n",
    "# #     print(soup1.find('h1',class_='restaurant_name').text)\n",
    "# #     print(soup1.find('span',class_='Restaurant__InfoAddress--Text').text)\n",
    "# #     print(body[1].find('td').text)\n",
    "# #     print(body[2].find('td').text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# KEY, VALUE >> DATAFRAME \n",
    "dat_r = {'name': nam, 'number':num, 'adr':adr, 'type':kind, 'review1':sev1, 'review2':sev2,'review3':sev3}\n",
    "dat = pd.DataFrame(dat_r)\n",
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 크롤링한 내용 파일로 내보내기\n",
    "dat.to_excel(\"korean1008.xlsx\", encoding=\"utf-8\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#리뷰들만 모아서 파일로 만들기\n",
    "dat_review = {'review1':sev1, 'review2':sev2,'review3':sev3}\n",
    "dat2 = pd.DataFrame(dat_review)\n",
    "dat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2.to_excel(\"korean_review.xlsx\", encoding=\"utf-8\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
